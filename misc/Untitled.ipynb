{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89717b54-f7cf-4ee4-904d-7d845cbae102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "26/26 - 2s - 60ms/step - accuracy: 0.5603 - loss: 0.8965 - val_accuracy: 0.5490 - val_loss: 0.6758\n",
      "Epoch 2/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.6059 - loss: 0.7930 - val_accuracy: 0.6324 - val_loss: 0.6435\n",
      "Epoch 3/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.5985 - loss: 0.7591 - val_accuracy: 0.6716 - val_loss: 0.6181\n",
      "Epoch 4/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.6441 - loss: 0.7534 - val_accuracy: 0.7010 - val_loss: 0.5994\n",
      "Epoch 5/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.6441 - loss: 0.7319 - val_accuracy: 0.6961 - val_loss: 0.5821\n",
      "Epoch 6/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.6724 - loss: 0.6830 - val_accuracy: 0.7010 - val_loss: 0.5634\n",
      "Epoch 7/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7266 - loss: 0.6283 - val_accuracy: 0.7206 - val_loss: 0.5475\n",
      "Epoch 8/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7254 - loss: 0.6113 - val_accuracy: 0.7304 - val_loss: 0.5334\n",
      "Epoch 9/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7106 - loss: 0.6035 - val_accuracy: 0.7402 - val_loss: 0.5200\n",
      "Epoch 10/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7217 - loss: 0.6064 - val_accuracy: 0.7647 - val_loss: 0.5075\n",
      "Epoch 11/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7106 - loss: 0.5842 - val_accuracy: 0.7696 - val_loss: 0.4965\n",
      "Epoch 12/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7672 - loss: 0.5283 - val_accuracy: 0.7745 - val_loss: 0.4870\n",
      "Epoch 13/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7463 - loss: 0.5289 - val_accuracy: 0.7941 - val_loss: 0.4808\n",
      "Epoch 14/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7599 - loss: 0.5273 - val_accuracy: 0.7990 - val_loss: 0.4743\n",
      "Epoch 15/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7796 - loss: 0.4841 - val_accuracy: 0.8088 - val_loss: 0.4685\n",
      "Epoch 16/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7635 - loss: 0.5209 - val_accuracy: 0.8235 - val_loss: 0.4643\n",
      "Epoch 17/150\n",
      "26/26 - 0s - 4ms/step - accuracy: 0.7968 - loss: 0.4783 - val_accuracy: 0.8235 - val_loss: 0.4613\n",
      "Epoch 18/150\n",
      "26/26 - 0s - 4ms/step - accuracy: 0.7833 - loss: 0.5014 - val_accuracy: 0.8235 - val_loss: 0.4559\n",
      "Epoch 19/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7845 - loss: 0.4757 - val_accuracy: 0.8235 - val_loss: 0.4529\n",
      "Epoch 20/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7771 - loss: 0.4823 - val_accuracy: 0.8235 - val_loss: 0.4507\n",
      "Epoch 21/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8214 - loss: 0.4439 - val_accuracy: 0.8284 - val_loss: 0.4496\n",
      "Epoch 22/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7968 - loss: 0.4826 - val_accuracy: 0.8284 - val_loss: 0.4471\n",
      "Epoch 23/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8030 - loss: 0.4439 - val_accuracy: 0.8284 - val_loss: 0.4434\n",
      "Epoch 24/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8251 - loss: 0.4391 - val_accuracy: 0.8333 - val_loss: 0.4396\n",
      "Epoch 25/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7993 - loss: 0.4687 - val_accuracy: 0.8333 - val_loss: 0.4371\n",
      "Epoch 26/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8300 - loss: 0.4502 - val_accuracy: 0.8333 - val_loss: 0.4346\n",
      "Epoch 27/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.7993 - loss: 0.4489 - val_accuracy: 0.8431 - val_loss: 0.4312\n",
      "Epoch 28/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8017 - loss: 0.4287 - val_accuracy: 0.8431 - val_loss: 0.4300\n",
      "Epoch 29/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8103 - loss: 0.4528 - val_accuracy: 0.8480 - val_loss: 0.4278\n",
      "Epoch 30/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8042 - loss: 0.4400 - val_accuracy: 0.8480 - val_loss: 0.4267\n",
      "Epoch 31/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8079 - loss: 0.4678 - val_accuracy: 0.8480 - val_loss: 0.4259\n",
      "Epoch 32/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8214 - loss: 0.4569 - val_accuracy: 0.8480 - val_loss: 0.4241\n",
      "Epoch 33/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8030 - loss: 0.4438 - val_accuracy: 0.8480 - val_loss: 0.4226\n",
      "Epoch 34/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8067 - loss: 0.4243 - val_accuracy: 0.8480 - val_loss: 0.4212\n",
      "Epoch 35/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8227 - loss: 0.4303 - val_accuracy: 0.8480 - val_loss: 0.4199\n",
      "Epoch 36/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8190 - loss: 0.4339 - val_accuracy: 0.8480 - val_loss: 0.4185\n",
      "Epoch 37/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8239 - loss: 0.4358 - val_accuracy: 0.8529 - val_loss: 0.4169\n",
      "Epoch 38/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8288 - loss: 0.4176 - val_accuracy: 0.8529 - val_loss: 0.4156\n",
      "Epoch 39/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8103 - loss: 0.4276 - val_accuracy: 0.8529 - val_loss: 0.4145\n",
      "Epoch 40/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8251 - loss: 0.4110 - val_accuracy: 0.8529 - val_loss: 0.4142\n",
      "Epoch 41/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8042 - loss: 0.4362 - val_accuracy: 0.8529 - val_loss: 0.4122\n",
      "Epoch 42/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8227 - loss: 0.4158 - val_accuracy: 0.8529 - val_loss: 0.4122\n",
      "Epoch 43/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8276 - loss: 0.4105 - val_accuracy: 0.8529 - val_loss: 0.4094\n",
      "Epoch 44/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8227 - loss: 0.4023 - val_accuracy: 0.8529 - val_loss: 0.4083\n",
      "Epoch 45/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8140 - loss: 0.4101 - val_accuracy: 0.8529 - val_loss: 0.4079\n",
      "Epoch 46/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8300 - loss: 0.4133 - val_accuracy: 0.8529 - val_loss: 0.4072\n",
      "Epoch 47/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8276 - loss: 0.4280 - val_accuracy: 0.8529 - val_loss: 0.4066\n",
      "Epoch 48/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8288 - loss: 0.3973 - val_accuracy: 0.8529 - val_loss: 0.4062\n",
      "Epoch 49/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8448 - loss: 0.3848 - val_accuracy: 0.8529 - val_loss: 0.4057\n",
      "Epoch 50/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8128 - loss: 0.4324 - val_accuracy: 0.8529 - val_loss: 0.4053\n",
      "Epoch 51/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8325 - loss: 0.3850 - val_accuracy: 0.8529 - val_loss: 0.4034\n",
      "Epoch 52/150\n",
      "26/26 - 0s - 4ms/step - accuracy: 0.8399 - loss: 0.3753 - val_accuracy: 0.8529 - val_loss: 0.4029\n",
      "Epoch 53/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8534 - loss: 0.3917 - val_accuracy: 0.8529 - val_loss: 0.4023\n",
      "Epoch 54/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8350 - loss: 0.3746 - val_accuracy: 0.8578 - val_loss: 0.4026\n",
      "Epoch 55/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8264 - loss: 0.3953 - val_accuracy: 0.8578 - val_loss: 0.4021\n",
      "Epoch 56/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8399 - loss: 0.3935 - val_accuracy: 0.8578 - val_loss: 0.4011\n",
      "Epoch 57/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8436 - loss: 0.3931 - val_accuracy: 0.8627 - val_loss: 0.4006\n",
      "Epoch 58/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8177 - loss: 0.4353 - val_accuracy: 0.8627 - val_loss: 0.3994\n",
      "Epoch 59/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8337 - loss: 0.4010 - val_accuracy: 0.8627 - val_loss: 0.3974\n",
      "Epoch 60/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8473 - loss: 0.3667 - val_accuracy: 0.8627 - val_loss: 0.3958\n",
      "Epoch 61/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8547 - loss: 0.3578 - val_accuracy: 0.8627 - val_loss: 0.3954\n",
      "Epoch 62/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8473 - loss: 0.3805 - val_accuracy: 0.8627 - val_loss: 0.3955\n",
      "Epoch 63/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8190 - loss: 0.3961 - val_accuracy: 0.8578 - val_loss: 0.3946\n",
      "Epoch 64/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8337 - loss: 0.3807 - val_accuracy: 0.8676 - val_loss: 0.3928\n",
      "Epoch 65/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8436 - loss: 0.3925 - val_accuracy: 0.8627 - val_loss: 0.3929\n",
      "Epoch 66/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8473 - loss: 0.3737 - val_accuracy: 0.8529 - val_loss: 0.3925\n",
      "Epoch 67/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8461 - loss: 0.3858 - val_accuracy: 0.8529 - val_loss: 0.3923\n",
      "Epoch 68/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8411 - loss: 0.4050 - val_accuracy: 0.8529 - val_loss: 0.3914\n",
      "Epoch 69/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8498 - loss: 0.3721 - val_accuracy: 0.8529 - val_loss: 0.3913\n",
      "Epoch 70/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8547 - loss: 0.3627 - val_accuracy: 0.8529 - val_loss: 0.3902\n",
      "Epoch 71/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8448 - loss: 0.3594 - val_accuracy: 0.8529 - val_loss: 0.3898\n",
      "Epoch 72/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8399 - loss: 0.3674 - val_accuracy: 0.8529 - val_loss: 0.3894\n",
      "Epoch 73/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8621 - loss: 0.3284 - val_accuracy: 0.8529 - val_loss: 0.3885\n",
      "Epoch 74/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8461 - loss: 0.3424 - val_accuracy: 0.8480 - val_loss: 0.3882\n",
      "Epoch 75/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8473 - loss: 0.3676 - val_accuracy: 0.8480 - val_loss: 0.3884\n",
      "Epoch 76/150\n",
      "26/26 - 0s - 4ms/step - accuracy: 0.8547 - loss: 0.3724 - val_accuracy: 0.8480 - val_loss: 0.3887\n",
      "Epoch 77/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8473 - loss: 0.3702 - val_accuracy: 0.8480 - val_loss: 0.3880\n",
      "Epoch 78/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8436 - loss: 0.3917 - val_accuracy: 0.8480 - val_loss: 0.3861\n",
      "Epoch 79/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8362 - loss: 0.3794 - val_accuracy: 0.8480 - val_loss: 0.3856\n",
      "Epoch 80/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8436 - loss: 0.3758 - val_accuracy: 0.8480 - val_loss: 0.3853\n",
      "Epoch 81/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8608 - loss: 0.3503 - val_accuracy: 0.8480 - val_loss: 0.3847\n",
      "Epoch 82/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8608 - loss: 0.3490 - val_accuracy: 0.8480 - val_loss: 0.3847\n",
      "Epoch 83/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8350 - loss: 0.3815 - val_accuracy: 0.8480 - val_loss: 0.3843\n",
      "Epoch 84/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8387 - loss: 0.3834 - val_accuracy: 0.8480 - val_loss: 0.3837\n",
      "Epoch 85/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8498 - loss: 0.3608 - val_accuracy: 0.8480 - val_loss: 0.3836\n",
      "Epoch 86/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8584 - loss: 0.3612 - val_accuracy: 0.8480 - val_loss: 0.3832\n",
      "Epoch 87/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8448 - loss: 0.3673 - val_accuracy: 0.8480 - val_loss: 0.3835\n",
      "Epoch 88/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8584 - loss: 0.3540 - val_accuracy: 0.8480 - val_loss: 0.3829\n",
      "Epoch 89/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8498 - loss: 0.3496 - val_accuracy: 0.8480 - val_loss: 0.3835\n",
      "Epoch 90/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8559 - loss: 0.3538 - val_accuracy: 0.8480 - val_loss: 0.3830\n",
      "Epoch 91/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8510 - loss: 0.3618 - val_accuracy: 0.8529 - val_loss: 0.3820\n",
      "Epoch 92/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8682 - loss: 0.3529 - val_accuracy: 0.8480 - val_loss: 0.3815\n",
      "Epoch 93/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8461 - loss: 0.3570 - val_accuracy: 0.8480 - val_loss: 0.3812\n",
      "Epoch 94/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8387 - loss: 0.3744 - val_accuracy: 0.8529 - val_loss: 0.3811\n",
      "Epoch 95/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8399 - loss: 0.3612 - val_accuracy: 0.8529 - val_loss: 0.3810\n",
      "Epoch 96/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8707 - loss: 0.3366 - val_accuracy: 0.8529 - val_loss: 0.3795\n",
      "Epoch 97/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8362 - loss: 0.3689 - val_accuracy: 0.8529 - val_loss: 0.3787\n",
      "Epoch 98/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8534 - loss: 0.3668 - val_accuracy: 0.8578 - val_loss: 0.3778\n",
      "Epoch 99/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8744 - loss: 0.3338 - val_accuracy: 0.8578 - val_loss: 0.3768\n",
      "Epoch 100/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8485 - loss: 0.3403 - val_accuracy: 0.8578 - val_loss: 0.3769\n",
      "Epoch 101/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8658 - loss: 0.3444 - val_accuracy: 0.8578 - val_loss: 0.3766\n",
      "Epoch 102/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8534 - loss: 0.3442 - val_accuracy: 0.8578 - val_loss: 0.3751\n",
      "Epoch 103/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8461 - loss: 0.3765 - val_accuracy: 0.8578 - val_loss: 0.3748\n",
      "Epoch 104/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8534 - loss: 0.3680 - val_accuracy: 0.8578 - val_loss: 0.3749\n",
      "Epoch 105/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8411 - loss: 0.3699 - val_accuracy: 0.8578 - val_loss: 0.3742\n",
      "Epoch 106/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8522 - loss: 0.3368 - val_accuracy: 0.8578 - val_loss: 0.3736\n",
      "Epoch 107/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8424 - loss: 0.3600 - val_accuracy: 0.8578 - val_loss: 0.3739\n",
      "Epoch 108/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8399 - loss: 0.3364 - val_accuracy: 0.8578 - val_loss: 0.3750\n",
      "Epoch 109/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8411 - loss: 0.3782 - val_accuracy: 0.8578 - val_loss: 0.3738\n",
      "Epoch 110/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8596 - loss: 0.3330 - val_accuracy: 0.8578 - val_loss: 0.3745\n",
      "Epoch 111/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8584 - loss: 0.3318 - val_accuracy: 0.8578 - val_loss: 0.3752\n",
      "Epoch 112/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8522 - loss: 0.3247 - val_accuracy: 0.8578 - val_loss: 0.3748\n",
      "Epoch 113/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8510 - loss: 0.3375 - val_accuracy: 0.8578 - val_loss: 0.3754\n",
      "Epoch 114/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8707 - loss: 0.3293 - val_accuracy: 0.8578 - val_loss: 0.3754\n",
      "Epoch 115/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8584 - loss: 0.3450 - val_accuracy: 0.8578 - val_loss: 0.3752\n",
      "Epoch 116/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8559 - loss: 0.3506 - val_accuracy: 0.8578 - val_loss: 0.3762\n",
      "Epoch 117/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8510 - loss: 0.3454 - val_accuracy: 0.8578 - val_loss: 0.3751\n",
      "Epoch 118/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8473 - loss: 0.3512 - val_accuracy: 0.8578 - val_loss: 0.3740\n",
      "Epoch 119/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8584 - loss: 0.3304 - val_accuracy: 0.8578 - val_loss: 0.3741\n",
      "Epoch 120/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8670 - loss: 0.3274 - val_accuracy: 0.8578 - val_loss: 0.3732\n",
      "Epoch 121/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8498 - loss: 0.3676 - val_accuracy: 0.8578 - val_loss: 0.3724\n",
      "Epoch 122/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8707 - loss: 0.3297 - val_accuracy: 0.8578 - val_loss: 0.3719\n",
      "Epoch 123/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8510 - loss: 0.3644 - val_accuracy: 0.8578 - val_loss: 0.3714\n",
      "Epoch 124/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8547 - loss: 0.3539 - val_accuracy: 0.8578 - val_loss: 0.3708\n",
      "Epoch 125/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8682 - loss: 0.3427 - val_accuracy: 0.8578 - val_loss: 0.3708\n",
      "Epoch 126/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8534 - loss: 0.3348 - val_accuracy: 0.8578 - val_loss: 0.3711\n",
      "Epoch 127/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8399 - loss: 0.3574 - val_accuracy: 0.8578 - val_loss: 0.3710\n",
      "Epoch 128/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8633 - loss: 0.3239 - val_accuracy: 0.8578 - val_loss: 0.3703\n",
      "Epoch 129/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8547 - loss: 0.3347 - val_accuracy: 0.8578 - val_loss: 0.3691\n",
      "Epoch 130/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8584 - loss: 0.3356 - val_accuracy: 0.8578 - val_loss: 0.3696\n",
      "Epoch 131/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8707 - loss: 0.3243 - val_accuracy: 0.8578 - val_loss: 0.3693\n",
      "Epoch 132/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8387 - loss: 0.3331 - val_accuracy: 0.8578 - val_loss: 0.3688\n",
      "Epoch 133/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8461 - loss: 0.3538 - val_accuracy: 0.8578 - val_loss: 0.3686\n",
      "Epoch 134/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8621 - loss: 0.3409 - val_accuracy: 0.8578 - val_loss: 0.3688\n",
      "Epoch 135/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8732 - loss: 0.3477 - val_accuracy: 0.8578 - val_loss: 0.3689\n",
      "Epoch 136/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8670 - loss: 0.3305 - val_accuracy: 0.8578 - val_loss: 0.3696\n",
      "Epoch 137/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8547 - loss: 0.3409 - val_accuracy: 0.8529 - val_loss: 0.3692\n",
      "Epoch 138/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8633 - loss: 0.3388 - val_accuracy: 0.8578 - val_loss: 0.3688\n",
      "Epoch 139/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8374 - loss: 0.3447 - val_accuracy: 0.8529 - val_loss: 0.3693\n",
      "Epoch 140/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8670 - loss: 0.3031 - val_accuracy: 0.8529 - val_loss: 0.3685\n",
      "Epoch 141/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8707 - loss: 0.3289 - val_accuracy: 0.8529 - val_loss: 0.3686\n",
      "Epoch 142/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8621 - loss: 0.3254 - val_accuracy: 0.8529 - val_loss: 0.3686\n",
      "Epoch 143/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8485 - loss: 0.3424 - val_accuracy: 0.8529 - val_loss: 0.3677\n",
      "Epoch 144/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8658 - loss: 0.3305 - val_accuracy: 0.8529 - val_loss: 0.3667\n",
      "Epoch 145/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8793 - loss: 0.3069 - val_accuracy: 0.8529 - val_loss: 0.3671\n",
      "Epoch 146/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8571 - loss: 0.3359 - val_accuracy: 0.8529 - val_loss: 0.3664\n",
      "Epoch 147/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8596 - loss: 0.3194 - val_accuracy: 0.8529 - val_loss: 0.3649\n",
      "Epoch 148/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8645 - loss: 0.3300 - val_accuracy: 0.8529 - val_loss: 0.3643\n",
      "Epoch 149/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8559 - loss: 0.3361 - val_accuracy: 0.8529 - val_loss: 0.3644\n",
      "Epoch 150/150\n",
      "26/26 - 0s - 3ms/step - accuracy: 0.8547 - loss: 0.3354 - val_accuracy: 0.8529 - val_loss: 0.3657\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       102\n",
      "           1       0.87      0.83      0.85       102\n",
      "\n",
      "    accuracy                           0.85       204\n",
      "   macro avg       0.85      0.85      0.85       204\n",
      "weighted avg       0.85      0.85      0.85       204\n",
      "\n",
      "ROC AUC Score: 0.8529411764705883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 1 Explanation:\n"
     ]
    },
    {
     "ename": "DimensionError",
     "evalue": "Length of features is not equal to the length of shap_values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Explanation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m     \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Summary Plot\u001b[39;00m\n\u001b[0;32m     78\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_test[:\u001b[38;5;241m10\u001b[39m], feature_names\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\plots\\_force.py:181\u001b[0m, in \u001b[0;36mforce\u001b[1;34m(base_value, shap_values, features, feature_names, out_names, link, plot_cmap, matplotlib, show, figsize, ordering_keys, ordering_keys_time_format, text_rotation, contribution_threshold)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(features) \u001b[38;5;241m==\u001b[39m shap_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    177\u001b[0m         emsg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You might be using an old format shap_values array with the base value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas the last column. In this case, just pass the array without the last column.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         )\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DimensionError(emsg)\n\u001b[0;32m    183\u001b[0m instance \u001b[38;5;241m=\u001b[39m Instance(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_names))), features)\n\u001b[0;32m    184\u001b[0m e \u001b[38;5;241m=\u001b[39m AdditiveExplanation(\n\u001b[0;32m    185\u001b[0m     base_value,\n\u001b[0;32m    186\u001b[0m     np\u001b[38;5;241m.\u001b[39msum(shap_values[\u001b[38;5;241m0\u001b[39m, :]) \u001b[38;5;241m+\u001b[39m base_value,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m     DenseData(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_names))), \u001b[38;5;28mlist\u001b[39m(feature_names))\n\u001b[0;32m    193\u001b[0m )\n",
      "\u001b[1;31mDimensionError\u001b[0m: Length of features is not equal to the length of shap_values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Loading\n",
    "data = pd.read_csv('heart2.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Handle missing values in numeric columns\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n",
    "\n",
    "# Feature and Target Split\n",
    "X = data.drop('HeartDisease', axis=1)\n",
    "y = data['HeartDisease']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, stratify=y_res, random_state=42)\n",
    "\n",
    "# Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32, shuffle=True, verbose=2)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_classes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9aaf3b-97fa-4c1a-8cda-ff09589129b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 1 Explanation:\n"
     ]
    },
    {
     "ename": "DimensionError",
     "evalue": "Length of features is not equal to the length of shap_values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Explanation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Directly index the NumPy array\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure X.columns is defined\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Save Model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimized_heart_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\plots\\_force.py:181\u001b[0m, in \u001b[0;36mforce\u001b[1;34m(base_value, shap_values, features, feature_names, out_names, link, plot_cmap, matplotlib, show, figsize, ordering_keys, ordering_keys_time_format, text_rotation, contribution_threshold)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(features) \u001b[38;5;241m==\u001b[39m shap_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    177\u001b[0m         emsg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You might be using an old format shap_values array with the base value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas the last column. In this case, just pass the array without the last column.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         )\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DimensionError(emsg)\n\u001b[0;32m    183\u001b[0m instance \u001b[38;5;241m=\u001b[39m Instance(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_names))), features)\n\u001b[0;32m    184\u001b[0m e \u001b[38;5;241m=\u001b[39m AdditiveExplanation(\n\u001b[0;32m    185\u001b[0m     base_value,\n\u001b[0;32m    186\u001b[0m     np\u001b[38;5;241m.\u001b[39msum(shap_values[\u001b[38;5;241m0\u001b[39m, :]) \u001b[38;5;241m+\u001b[39m base_value,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m     DenseData(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_names))), \u001b[38;5;28mlist\u001b[39m(feature_names))\n\u001b[0;32m    193\u001b[0m )\n",
      "\u001b[1;31mDimensionError\u001b[0m: Length of features is not equal to the length of shap_values!"
     ]
    }
   ],
   "source": [
    "# XAI using SHAP\n",
    "for i in range(10):\n",
    "    print(f\"Instance {i+1} Explanation:\")\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value[0], \n",
    "        shap_values[0][i], \n",
    "        features=X_test[i],  # Directly index the NumPy array\n",
    "        feature_names=X.columns,  # Ensure X.columns is defined\n",
    "        matplotlib=True\n",
    "    )\n",
    "# Save Model\n",
    "model.save('optimized_heart_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a60190-8e6e-43db-835c-9493e766c1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7d70d-33f2-4d76-b795-6632229c8541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
